{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zLEFCT0RBno",
        "outputId": "2710fd20-fb9d-48cb-8e6d-14cd4b8f4484"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unzipped from Drive.\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Tokenizer_cholladi_folder/cholloadai-2021.txt.zip'\n",
        "extract_path = '/content/extracted_zip'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "print(\"Unzipped from Drive.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1DU0m72RBk5",
        "outputId": "23a78a96-ddc7-4af4-9b3c-5c2b32fadd13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing: cholloadai-2021.txt.00.gz\n",
            "Processing: cholloadai-2021.txt.01.gz\n",
            "Processing: cholloadai-2021.txt.02.gz\n",
            "Processing: cholloadai-2021.txt.03.gz\n",
            "Processing: cholloadai-2021.txt.04.gz\n",
            "Processing: cholloadai-2021.txt.05.gz\n",
            "Processing: cholloadai-2021.txt.06.gz\n",
            "Processing: cholloadai-2021.txt.07.gz\n",
            "Processing: cholloadai-2021.txt.08.gz\n",
            "Processing: cholloadai-2021.txt.09.gz\n",
            "Processing: cholloadai-2021.txt.10.gz\n",
            "Processing: cholloadai-2021.txt.11.gz\n",
            "Processing: cholloadai-2021.txt.12.gz\n",
            "Processing: cholloadai-2021.txt.13.gz\n",
            "Processing: cholloadai-2021.txt.14.gz\n",
            "Processing: cholloadai-2021.txt.15.gz\n",
            "Processing: cholloadai-2021.txt.16.gz\n",
            "Processing: cholloadai-2021.txt.17.gz\n",
            "Processing: cholloadai-2021.txt.18.gz\n",
            "Processing: cholloadai-2021.txt.19.gz\n",
            "Processing: cholloadai-2021.txt.20.gz\n",
            "Processing: cholloadai-2021.txt.21.gz\n",
            "Processing: cholloadai-2021.txt.22.gz\n",
            "Processing: cholloadai-2021.txt.23.gz\n",
            "Processing: cholloadai-2021.txt.24.gz\n",
            "Processing: cholloadai-2021.txt.25.gz\n",
            "Processing: cholloadai-2021.txt.26.gz\n",
            "Processing: cholloadai-2021.txt.27.gz\n",
            "Processing: cholloadai-2021.txt.28.gz\n",
            "Processing: cholloadai-2021.txt.29.gz\n",
            "Processing: cholloadai-2021.txt.30.gz\n",
            "Processing: cholloadai-2021.txt.31.gz\n",
            "Processing: cholloadai-2021.txt.32.gz\n",
            "Processing: cholloadai-2021.txt.33.gz\n",
            "Processing: cholloadai-2021.txt.34.gz\n",
            "Processing: cholloadai-2021.txt.35.gz\n",
            "Processing: cholloadai-2021.txt.36.gz\n",
            "Processing: cholloadai-2021.txt.37.gz\n",
            "Processing: cholloadai-2021.txt.38.gz\n",
            "Processing: cholloadai-2021.txt.39.gz\n",
            "Processing: cholloadai-2021.txt.40.gz\n",
            "Processing: cholloadai-2021.txt.41.gz\n",
            "Processing: cholloadai-2021.txt.42.gz\n",
            "Processing: cholloadai-2021.txt.43.gz\n",
            "Processing: cholloadai-2021.txt.44.gz\n",
            "Processing: cholloadai-2021.txt.45.gz\n",
            "Processing: cholloadai-2021.txt.46.gz\n",
            "Processing: cholloadai-2021.txt.47.gz\n",
            "Processing: cholloadai-2021.txt.48.gz\n",
            "Processing: cholloadai-2021.txt.49.gz\n",
            "Processing: cholloadai-2021.txt.50.gz\n",
            "Processing: cholloadai-2021.txt.51.gz\n",
            "Processing: cholloadai-2021.txt.52.gz\n",
            "Processing: cholloadai-2021.txt.53.gz\n",
            "Processing: cholloadai-2021.txt.54.gz\n",
            "Processing: cholloadai-2021.txt.55.gz\n",
            "Processing: cholloadai-2021.txt.56.gz\n",
            "Processing: cholloadai-2021.txt.57.gz\n",
            "Processing: cholloadai-2021.txt.58.gz\n",
            "Processing: cholloadai-2021.txt.59.gz\n",
            "Processing: cholloadai-2021.txt.60.gz\n",
            "Processing: cholloadai-2021.txt.61.gz\n",
            "Processing: cholloadai-2021.txt.62.gz\n",
            "Processing: cholloadai-2021.txt.63.gz\n",
            "Processing: cholloadai-2021.txt.64.gz\n",
            "Processing: cholloadai-2021.txt.65.gz\n",
            "Processing: cholloadai-2021.txt.66.gz\n",
            "Processing: cholloadai-2021.txt.67.gz\n",
            "Processing: cholloadai-2021.txt.68.gz\n",
            "Processing: cholloadai-2021.txt.69.gz\n",
            "Processing: cholloadai-2021.txt.70.gz\n",
            "Processing: cholloadai-2021.txt.71.gz\n",
            "Processing: cholloadai-2021.txt.72.gz\n",
            " All .gz files have been concatenated into one file.\n"
          ]
        }
      ],
      "source": [
        "import gzip\n",
        "import os\n",
        "folder_path = \"/content/extracted_zip\"  # change if different\n",
        "output_file_path = \"/content/combined_output.txt\"  # final combined file\n",
        "with open(output_file_path, 'wb') as outfile:\n",
        "    for filename in sorted(os.listdir(folder_path)):\n",
        "        if filename.endswith(\".gz\"):\n",
        "            file_path = os.path.join(folder_path, filename)\n",
        "            print(f\"Processing: {filename}\")\n",
        "            with gzip.open(file_path, 'rb') as infile:\n",
        "                outfile.write(infile.read())\n",
        "\n",
        "print(\" All .gz files have been concatenated into one file.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "filepath='/content/sampled_1_percent.txt'\n",
        "filesize=os.path.getsize(filepath)\n",
        "print(filesize)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uwx-l83JPJKE",
        "outputId": "fccf606c-9cf8-4756-dffc-19c762a8ce52"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "222936961\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "with open(\"/content/combined_output.txt\", \"r\", encoding=\"utf-8\") as file:\n",
        "    total_lines = sum(1 for _ in file)\n",
        "sample_size = max(1, int(0.05 * total_lines))\n",
        "selected_line_numbers = sorted(random.sample(range(total_lines), sample_size))\n",
        "output_path = \"sampled_1_percent.txt\"\n",
        "with open(\"/content/combined_output.txt\", \"r\", encoding=\"utf-8\") as file, \\\n",
        "     open(output_path, \"w\", encoding=\"utf-8\") as output_file:\n",
        "\n",
        "    for idx, line in enumerate(file):\n",
        "        if selected_line_numbers and idx == selected_line_numbers[0]:\n",
        "            output_file.write(line)\n",
        "            selected_line_numbers.pop(0)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "RcqCAQDO-3s9"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "old_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "l9_Zm_z6-3pc"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_words_from_txt(path):\n",
        "    with open(path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            for word in line.strip().split():\n",
        "                yield word  # one word at a time\n",
        "\n",
        "\n",
        "new_tokenizer = old_tokenizer.train_new_from_iterator(get_words_from_txt(\"/content/sampled_1_percent.txt\"), vocab_size=52000)\n"
      ],
      "metadata": {
        "id": "hxU14IgT-3nH"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = new_tokenizer.encode('இந்த ஐட்டம் சுகந்தி அவ்வளவு நல்லவ கிடையாது')\n",
        "print(\"Token IDs:\", encoded)\n"
      ],
      "metadata": {
        "id": "7SYxzDEX-3fU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e504d5cf-6178-44c8-b36f-a2d0f518f809"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: [2, 239, 48, 1313, 37318, 4731, 874, 124, 3017, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = new_tokenizer.encode('மூடிட்டு போ வெக்கமா இல்ல உனக்கு ?')\n",
        "print(\"Token IDs:\", encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIH-fyovdPSl",
        "outputId": "c62092a1-0ba9-40b5-9d24-433b04cb731e"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: [2, 5743, 206, 221, 51502, 509, 692, 5756, 25, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(encoded)):\n",
        "  decoded=new_tokenizer.decode(encoded[i])\n",
        "  print(str(encoded[i])+\": \"+decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRQt1nlQdV-d",
        "outputId": "df524762-49bf-4698-a80b-db52edaf9359"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2: [CLS]\n",
            "5743: மூடி\n",
            "206: ##டடு\n",
            "221: போ\n",
            "51502: வெகக\n",
            "509: ##மா\n",
            "692: இலல\n",
            "5756: உனககு\n",
            "25: ?\n",
            "3: [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = new_tokenizer.encode('இந்த மாதிரி வீடியோ போட்டா நா அடிப்பேன் செருப்பால')\n",
        "print(\"Token IDs:\", encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QGtl1MpQdeEY",
        "outputId": "0b48822e-c472-4925-af56-37d976fa1a64"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: [2, 239, 2459, 2262, 27861, 1010, 16519, 30660, 42459, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(encoded)):\n",
        "  decoded=new_tokenizer.decode(encoded[i])\n",
        "  print(str(encoded[i])+\": \"+decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e8pVq29dhxL",
        "outputId": "7cdac4a1-ca89-4975-ce83-08ec3a132e17"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2: [CLS]\n",
            "239: இநத\n",
            "2459: மாதிரி\n",
            "2262: வடியோ\n",
            "27861: போடடா\n",
            "1010: நா\n",
            "16519: அடிப\n",
            "30660: ##பேன\n",
            "42459: செருபபால\n",
            "3: [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded = new_tokenizer.encode('என்னது மூக்குத்தி அம்மன் ஷூட்டிங் ah...dei என்னடா எல்லை மீறி போறீங்க')\n",
        "print(\"Token IDs:\", encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cEvVPK7Rdv3o",
        "outputId": "325c0814-f5da-4a3e-d5be-3c1b86323416"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token IDs: [2, 39978, 48666, 2873, 12952, 1, 18, 18, 18, 1, 19640, 3003, 3615, 45922, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(encoded)):\n",
        "  decoded=new_tokenizer.decode(encoded[i])\n",
        "  print(str(encoded[i])+\": \"+decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsw0bSOIdxUL",
        "outputId": "4c163a6f-792b-4d1c-fda5-64c7174e32be"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2: [CLS]\n",
            "39978: எனனது\n",
            "48666: மூககுததி\n",
            "2873: அமமன\n",
            "12952: ஷூடடிங\n",
            "1: [UNK]\n",
            "18: .\n",
            "18: .\n",
            "18: .\n",
            "1: [UNK]\n",
            "19640: எனனடா\n",
            "3003: எலலை\n",
            "3615: மறி\n",
            "45922: போறஙக\n",
            "3: [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_tokenizer.save_pretrained('bert_tokenizer_tamil')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3lG_AgesZwmS",
        "outputId": "0702aa55-d426-4820-e3ce-2823a08118f7"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bert_tokenizer_tamil/tokenizer_config.json',\n",
              " 'bert_tokenizer_tamil/special_tokens_map.json',\n",
              " 'bert_tokenizer_tamil/vocab.txt',\n",
              " 'bert_tokenizer_tamil/added_tokens.json',\n",
              " 'bert_tokenizer_tamil/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(encoded)):\n",
        "  decoded=new_tokenizer.decode(encoded[i])\n",
        "  print(str(encoded[i])+\": \"+decoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YSCbo-d6Yvq",
        "outputId": "4980bd67-6d95-471a-9d08-e9154e62c343"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2: [CLS]\n",
            "239: இநத\n",
            "48: ஐ\n",
            "1313: ##டடம\n",
            "37318: சுகநதி\n",
            "4731: அவவளவு\n",
            "874: நலல\n",
            "124: ##வ\n",
            "3017: கிடையாது\n",
            "3: [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tSkoEWH46JXI"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}